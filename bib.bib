@misc{Oracle2018,
author = {Oracle},
howpublished = {https://docs.oracle.com/javase/8/docs/index.html},
title = {{Java Platform Standard Edition 8 Documentation}},
year = {2018}
}
@misc{GoogleStatic2017,
abstract = {Google, 2014. Google Street View Image API, Available from: https://developers. google.com/maps/documentation/streetview/ (accessed October 2014).},
author = {{Google Maps}},
howpublished = {(accessed 15 June 2017)},
title = {{Google Static Maps API, Available from https://developers.google.com/maps/documentation/static-maps}},
year = {2017}
}
@article{Mihail2016,
abstract = {Automatically determining which pixels in an image view the sky, the problem of sky segmentation, is a critical pre-processing step for a wide variety of outdoor image in-terpretation problems, including horizon estimation, robot navigation and image geolocalization. Many methods for this problem have been proposed with recent work achiev-ing significant improvements on benchmark datasets. How-ever, such datasets are often constructed to contain images captured in favorable conditions and, therefore, do not re-flect the broad range of conditions with which a real-world vision system must cope. This paper presents the results of a large-scale empirical evaluation of the performance of three state-of-the-art approaches on a new dataset, which consists of roughly 100k images captured " in the wild " . The results show that the performance of these methods can be dramatically degraded by the local lighting and weather conditions. We propose a deep learning based variant of an ensemble solution that outperforms the methods we tested, in some cases achieving above 50{\%} relative reduction in misclassified pixels. While our results show there is room for improvement, our hope is that this dataset will encour-age others to improve the real-world performance of their algorithms.},
author = {Mihail, Radu P. and Workman, Scott and Bessinger, Zach and Jacobs, Nathan},
doi = {10.1109/WACV.2016.7477637},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Mihail et al. - 2016 - Sky segmentation in the wild An empirical study - 2016 IEEE Winter Conference on Applications of Computer Vision,.pdf:pdf},
isbn = {9781509006410},
journal = {2016 IEEE Winter Conference on Applications of Computer Vision, WACV 2016},
title = {{Sky segmentation in the wild: An empirical study}},
year = {2016}
}
@misc{GoogleMaps2017b,
author = {{Google Maps}},
howpublished = {(accessed 15 June 2017)},
title = {{Google Street View API, Available from https://developers.google.com/maps/documentation/streetview/}},
year = {2017}
}
@misc{GIMP2019,
author = {GIMP},
title = {{GNU Image Manipulation Program}},
url = {https://www.gimp.org/},
year = {2019}
}
@unpublished{Agarwal2016,
author = {Agarwal, Amit and Akchurin, Eldar and Basoglu, Chris and Chen, Guoguo and Cyphers, Scott and Droppo, Jasha and Eversole, Adam and Guenter, Brian and Hillebrand, Mark and Huang, Xuedong and Huang, Zhiheng and Ivanov, Vladimir and Kamenev, Alexey and Kranen, Philipp and Kuchaiev, Oleksii and Manousek, Wolfgang and May, Avner and Mitra, Bhaskar and Nano, Olivier and Navarro, Gaizka and Orlov, Alexey and Padmilac, Marko and Parthasarathi, Hari and Peng, Baolin and Reznichenko, Alexey and Seide, Frank and Seltzer, Michael L. and Slaney, Malcolm and Stolcke, Andreas and Wang, Huaming and Yao, Kaisheng and Yu, Dong and Zhang, Yu and Zweig, Geoffrey},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Agarwal et al. - 2016 - An Introduction to Computational Networks and the Computational Network Toolkit, MSR-TR-2014-112 - Unknown.pdf:pdf},
pages = {1--150},
title = {{An Introduction to Computational Networks and the Computational Network Toolkit, MSR-TR-2014-112, Microsoft}},
year = {2016}
}
@article{Bradski2000,
abstract = {@article{\{}opencv{\_}library, author = {\{}Bradski, G.{\}}, citeulike-article-id = {\{}2236121{\}}, journal = {\{}Dr. Dobb's Journal of Software Tools{\}}, keywords = {\{}bibtex-import{\}}, posted-at = {\{}2008-01-15 19:21:54{\}}, priority = {\{}4{\}}, title = {\{}{\{}The OpenCV Library{\}}{\}}, year = {\{}2000{\}} {\}}},
author = {Bradski, G.},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Bradski - 2000 - The OpenCV Library - Dr. Dobb's Journal of Software Tools.pdf:pdf},
journal = {Dr. Dobb's Journal of Software Tools},
title = {{The OpenCV Library}},
year = {2000}
}
@inproceedings{Christoudias2002,
abstract = {Christoudias, Christopher M., Bogdan Georgescu, and Peter Meer. 2002. Synergism in low level vision. In Proceedings of the sixteenth international conference on pattern recognition (ICPR 2002) held in Quebec City, Canada, August 11-15, 2002. New York, NY: IEEE Press. Available},
author = {Christoudias, Christopher M. and Georgescu, Bogdan and Meer, Peter},
booktitle = {Proceedings of the sixteenth international conference on pattern recognition (ICPR 2002) held in Quebec City, Canada, August 11-15, 2002. New York, NY},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Christoudias, Georgescu, Meer - 2002 - Synergism in Low Level Vision - Proceedings of the sixteenth international conference on pattern.pdf:pdf},
number = {2},
pages = {150--155},
publisher = {IEEE Press},
title = {{Synergism in Low Level Vision}},
year = {2002}
}
@inproceedings{Comaniciu1997,
abstract = {Comaniciu, Dorin and Peter Meer. 1997. Robust analysis of feature spaces: Color image segmentation. In Proceedings of the 1997 conference on computer vision and pattern recognition (CVPR '97) held in San Juan, Puerto Rico, June 17-19, 1997, 750-755. New York, NY: IEEE Press. Available http://www.caip.rutgers.edu/riul/research/papers/pdf/feature.pdf.},
address = {New York},
author = {Comaniciu, Dorin and Meer, Peter},
booktitle = {Proceedings of the 1997 conference on computer vision and pattern recognition (CVPR '97) held in San Juan, Puerto Rico, June 17-19, 1997, 750-755.},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Comaniciu, Meer - 1997 - Robust Analysis of Feature Spaces Color Image Segmentation - Proceedings of the 1997 conference on computer v.pdf:pdf},
pages = {750--755},
publisher = {IEEE Press},
year = {1997}
}
@article{Comaniciu2002,
abstract = {A general nonparametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure, the mean shift. We prove for discrete data the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators of location is also established. Algorithms for two low-level vision tasks, discontinuity preserving smoothing and image segmentation, are described as applications. In these algorithms, the only user set parameter is the resolution of the analysis and either gray level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.},
author = {Comaniciu, Dorin and Meer, Peter},
doi = {10.1109/34.1000236},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Comaniciu, Meer - 2002 - Mean shift A robust approach toward feature space analysis - IEEE Transactions on Pattern Analysis and Machine.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Clustering,Feature space,Image segmentation,Image smoothing,Low-level vision,Mean shift},
number = {5},
pages = {603--619},
pmid = {19073269},
title = {{Mean shift: A robust approach toward feature space analysis}},
volume = {24},
year = {2002}
}
@inproceedings{Hassannejad2016,
author = {Hassannejad, Hamid and Matrella, Guido and Ciampolini, Paolo and Mordonini, Monica and Cagnoni, Stefano},
booktitle = {MADiMa'16, October 16 2016, Amsterdam, The Netherlands},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Hassannejad et al. - 2016 - Food Image Recognition Using Very Deep Convolutional Networks - MADiMa'16, October 16 2016, Amsterdam, The.pdf:pdf},
isbn = {9781450345200},
keywords = {automatic diet monitoring,cnn,convolutional neural networks,food recognition,inception},
pages = {41--49},
title = {{Food Image Recognition Using Very Deep Convolutional Networks}},
year = {2016}
}
@inproceedings{Laungrungthip2008,
abstract = {A device for predicting the solar exposure at a location operates by gathering image data from that location with a known camera orientation. The image data is then processed to identify the sky regions and the solar exposure is predicted using a standard sun path model and tracing the rays from the sun through the processed images. Critical to the success of this technique is the image processing used to separate the sky from the rest of the image. This work is concerned with developing a technique which can do this for images taken under different weather conditions. The general approach to separate the sky from the rest of the image is to use the Canny edge detector and the morphology closing algorithm to find the regions in the image. The brightness and area of each region are then used to determine which regions are sky. The FloodFill algorithm is applied to identify all pixels in each sky region.},
author = {Laungrungthip, N. and McKinnon, A. E. and Churcher, C. D. and Unsworth, K.},
booktitle = {2008 23rd International Conference Image and Vision Computing New Zealand, IVCNZ},
doi = {10.1109/IVCNZ.2008.4762101},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Laungrungthip et al. - 2008 - Edge-based detection of sky regions in images for solar exposure prediction - 2008 23rd International Conf.pdf:pdf},
isbn = {9781424425822},
keywords = {Image processing,Image segmentation,Skyline,Solar exposure},
title = {{Edge-based detection of sky regions in images for solar exposure prediction}},
year = {2008}
}
@article{Middel2017,
abstract = {{\textless}p{\textgreater}The Sky View Factor (SVF) is a dimension-reduced representation of urban form and one of the major variables in radiation models that estimate outdoor thermal comfort. Common ways of retrieving SVFs in urban environments include capturing fisheye photographs or creating a digital 3D city or elevation model of the environment. Such techniques have previously been limited due to a lack of imagery or lack of full scale detailed models of urban areas. We developed a web based tool that automatically generates synthetic hemispherical fisheye views from Google Earth at arbitrary spatial resolution and calculates the corresponding SVFs through equiangular projection. SVF results were validated using Google Maps Street View and compared to results from other SVF calculation tools. We generated 5-meter resolution SVF maps for two neighborhoods in Phoenix, Arizona to illustrate fine-scale variations of intra-urban horizon limitations due to urban form and vegetation. To demonstrate the utility of our synthetic fisheye approach for heat stress applications, we automated a radiation model to generate outdoor thermal comfort maps for Arizona State University's Tempe campus for a hot summer day using synthetic fisheye photos and on-site meteorological data. Model output was tested against mobile transect measurements of the six-directional radiant flux density. Based on the thermal comfort maps, we implemented a pedestrian routing algorithm that is optimized for distance and thermal comfort preferences. Our synthetic fisheye approach can help planners assess urban design and tree planting strategies to maximize thermal comfort outcomes and can support heat hazard mitigation in urban areas.{\textless}/p{\textgreater}},
author = {Middel, Ariane and Lukasczyk, Jonas and Maciejewski, Ross},
doi = {10.17645/up.v2i1.855},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Middel, Lukasczyk, Maciejewski - 2017 - Sky View Factors from Synthetic Fisheye Photos for Thermal Comfort Routing—A Case Study in Phoeni.:},
issn = {2183-7635},
journal = {Urban Planning},
keywords = {climate-sensitive urban design,desert city,heat,mrt,outdoor thermal comfort,pet,routing,sky view factor,thermal comfort,urban form,walkability},
number = {1},
pages = {19},
title = {{Sky View Factors from Synthetic Fisheye Photos for Thermal Comfort Routing—A Case Study in Phoenix, Arizona}},
volume = {2},
year = {2017}
}
@article{Middel2018,
author = {Middel, Ariane and Lukasczyk, Jonas and Maciejewski, Ross and Demuzere, Matthias and Roth, Matthias},
doi = {10.1016/j.uclim.2018.05.004},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Middel et al. - 2018 - Sky View Factor Footprints for Urban Climate Modeling - Urban Climate.pdf:pdf},
issn = {22120955},
journal = {Urban Climate},
pages = {120--134},
publisher = {Elsevier},
title = {{Sky View Factor Footprints for Urban Climate Modeling}},
volume = {25},
year = {2018}
}
@phdthesis{Pangburn2002,
author = {Pangburn, Brian Edward},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Pangburn - 2002 - EXPERIENCE-BASED LANGUAGE ACQUISITION A COMPUTATIONAL MODEL OF HUMAN LANGUAGE ACQUISITION - Unknown.pdf:pdf},
school = {Louisiana State University},
title = {{Experience-Based Language Acquisition: A Computational Model Of Human Language Acquisition}},
type = {PhD},
year = {2002}
}
@inproceedings{Sobel1968,
abstract = {Sobel, I., Feldman, G., "A 3x3 Isotropic Gradient Operator for Image Processing", presented at the Stanford Artificial Intelligence Project (SAIL) in 1968. (17) (PDF) An Isotropic 3x3 Image Gradient Operator. Available from: https://www.researchgate.net/publication/239398674{\_}An{\_}Isotropic{\_}3x3{\_}Image{\_}Gradient{\_}Operator [accessed Jan 25 2019].},
author = {Sobel, I. and Feldman, G},
booktitle = {Stanford Artificial Intelligence Project (SAIL)},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Sobel, Feldman - 1968 - A 3x3 Isotropic Gradient Operator for Image Processing - Stanford Artificial Intelligence Project (SAIL).pdf:pdf},
title = {{A 3x3 Isotropic Gradient Operator for Image Processing}},
year = {1968}
}
@inproceedings{Szegedy2015a,
abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2{\%} top-1 and 5.6{\%} top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5{\%} top-5 error on the validation set (3.6{\%} error on the test set) and 17.3{\%} top-1 error on the validation set.},
archivePrefix = {arXiv},
arxivId = {1512.00567},
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
doi = {10.1109/CVPR.2016.308},
eprint = {1512.00567},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Szegedy et al. - 2016 - Rethinking the Inception Architecture for Computer Vision - The IEEE Conference on Computer Vision and Pattern R.pdf:pdf},
isbn = {978-1-4673-8851-1},
issn = {08866236},
pmid = {8190083},
title = {{Rethinking the Inception Architecture for Computer Vision}},
year = {2016}
}
@inproceedings{Wang2015a,
author = {Wang, Chi-Wei and Ding, Jian-Jiun and Chen, Po-Jen},
booktitle = {Proceedings of APSIPA Annual Summit and Conference 2015},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Wang, Ding, Chen - 2015 - An Efficient Sky Detection Algorithm Based on Hybrid Probability Model - Proceedings of APSIPA Annual Summit a.pdf:pdf},
isbn = {9789881476807},
pages = {919--922},
title = {{An Efficient Sky Detection Algorithm Based on Hybrid Probability Model}},
year = {2015}
}
@inproceedings{Xia2017,
author = {Xia, Xiaoling and Xu, Cui and Nan, Bing},
booktitle = {2017 2nd International Conference on Image, Vision and Computing (ICIVC)},
doi = {10.1109/ICIVC.2017.7984661},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Xia, Xu, Nan - 2017 - Inception-v3 for Flower Classification - 2017 2nd International Conference on Image, Vision and Computing (ICIVC).pdf:pdf},
isbn = {9781509062386},
keywords = {-flower classification,inception-v3,tensorflow},
pages = {783--787},
publisher = {IEEE},
title = {{Inception-v3 for Flower Classification}},
year = {2017}
}
@techreport{Yu2015,
author = {Yu, Dong and Eversole, Adam and Seltzer, Michael L and Yao, Kaisheng and Huang, Zhiheng and Guenter, Brian and Kuchaiev, Oleksii and Zhang, Yu and Seide, Frank and Wang, Huaming and Droppo, Jasha and Zweig, Geoffrey and Rossbach, Chris and Currey, Jon and Gao, Jie and May, Avner and Peng, Baolin and Stolcke, Andreas and Slaney, Malcolm},
booktitle = {Microsoft Technical Report MSR-TR-2014--112},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Yu et al. - 2015 - An Introduction to Computational Networks and the Computational Network Toolkit. Microsoft Technical Report MSR-TR-20.pdf:pdf},
institution = {Microsoft},
title = {{An Introduction to Computational Networks and the Computational Network Toolkit. Microsoft Technical Report MSR-TR-2014--112}},
year = {2015}
}
@article{Luo2002,
abstract = {( Volume: 11 , Issue: 3 , Mar 2002 )},
author = {Luo, Jiebo and Etz, Stephen P},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Luo, Etz - 2002 - A Physical Model-Based Approach to Detecting Sky in Photographic Images - IEEE Transactions on Image Processing.pdf:pdf},
journal = {IEEE Transactions on Image Processing},
number = {3},
pages = {201--212},
title = {{A Physical Model-Based Approach to Detecting Sky in Photographic Images}},
volume = {11},
year = {2002}
}
@inproceedings{Gallagher2004,
author = {Gallagher, Andrew C and Luo, Jiebo and Hao, Wei},
booktitle = {2004 International Conference on Image Processing, 2004. ICIP '04.},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Gallagher, Luo, Hao - 2004 - Improved blue sky detection using polynomial model fit - 2004 International Conference on Image Processing,.pdf:pdf},
isbn = {0780385543},
pages = {2367--2370},
title = {{Improved blue sky detection using polynomial model fit}},
year = {2004}
}
@article{Zafarifar2007,
author = {Zafarifar, Bahman and de With, Peter H. N.},
doi = {10.1109/ICCE.2007.341568},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/04146205.pdf:pdf},
journal = {2007 Digest of Technical Papers International Conference on Consumer Electronics},
title = {{Blue Sky Detection for Content-based Television Picture Quality Enhancement}},
year = {2007}
}
@inproceedings{Schmitt2009,
author = {Schmitt, Frank and Priese, Lutz},
booktitle = {VISAPP 2009 - Proceedings of the Fourth International Conference on Computer Vision Theory and Applications, Lisboa, Portugal, February 5-8, 2009 - Volume 2},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Schmitt, Priese - 2009 - SKY DETECTION IN CSC-SEGMENTED COLOR IMAGES - VISAPP 2009 - Proceedings of the Fourth International Conference.pdf:pdf},
title = {{Sky Detection In CSC-Segmented Color Images}},
year = {2009}
}
@article{Ettinger2003,
author = {Ettinger, Scott M and Nechyba, Michael C and Waszak, Martin and Ifju, Peter G},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Ettinger et al. - 2003 - Vision-Guided Flight Stability and Control for Micro Air Vehicles - Advanced Robotics.pdf:pdf},
journal = {Advanced Robotics},
number = {7},
pages = {617--640},
title = {{Vision-Guided Flight Stability and Control for Micro Air Vehicles}},
volume = {17},
year = {2003}
}
@article{Shen2013,
author = {Shen, Yehu and Wang, Qicong},
doi = {10.5772/56884},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Shen, Wang - 2013 - Sky Region Detection in a Single Image for Autonomous Ground Robot Navigation - International Journal of Advanced Ro.pdf:pdf},
journal = {International Journal of Advanced Robotic Systems},
keywords = {energy,function optimization,gradient information,robot navigation,sky detection},
pages = {1--13},
title = {{Sky Region Detection in a Single Image for Autonomous Ground Robot Navigation}},
volume = {10},
year = {2013}
}
@article{Zhijie2014,
author = {Zhijie, Zhao and Qian, Wu and Huadong, Sun and Xuesong, Jin},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Zhijie et al. - 2014 - An Effective Method for Sky Region Detection - Advanced Science and Technology Letters.pdf:pdf},
journal = {Advanced Science and Technology Letters},
keywords = {color,gradient information,s ky detection,sky border points},
pages = {96--100},
title = {{An Effective Method for Sky Region Detection}},
volume = {77},
year = {2014}
}
@article{Zhijie2015,
author = {Zhijie, Zhao and Qian, Wu and Huadong, Sun and Xuesong, Jin and Qin, Tian and Xiaoying, Sun},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Zhijie et al. - 2015 - A Novel Sky Region Detection Algorithm Based On Border Points - International Journal of Signal Processing, Image.pdf:pdf},
journal = {International Journal of Signal Processing, Image Processing and Pattern Recognition},
keywords = {border points,border position function,energy function,sky detection},
number = {3},
pages = {281--290},
title = {{A Novel Sky Region Detection Algorithm Based On Border Points}},
volume = {8},
year = {2015}
}
@article{Grimmond2001,
author = {Grimmond, C.S.B. and Potter, S.K. and Zutter, H.N. and Souch, C.},
doi = {10.1002/joc.659},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Grimmond et al. - 2001 - Rapid methods to estimate sky-view factors applied to urban areas - International Journal of Climatology.pdf:pdf},
issn = {0899-8418},
journal = {International Journal of Climatology},
keywords = {camera with fisheye lens,digital,plant canopy analyser,sky-view factor},
number = {7},
pages = {903--913},
title = {{Rapid methods to estimate sky-view factors applied to urban areas}},
volume = {21},
year = {2001}
}
@article{Chapman2004,
author = {Chapman, L. and Thornes, J. E.},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Chapman, Thornes - 2004 - Real-Time Sky-View Factor Calculation and Approximation - Journal Of Atmospheric And Oceanic Technology.pdf:pdf},
journal = {Journal Of Atmospheric And Oceanic Technology},
pages = {730--741},
title = {{Real-Time Sky-View Factor Calculation and Approximation}},
volume = {21},
year = {2004}
}
@article{Ali-Toudert2007,
author = {Ali-Toudert, Fazia and Mayer, Helmut},
doi = {10.1016/j.solener.2006.10.007},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Downloaded-disable/Ali-Toudert, Mayer - 2007 - Effects of asymmetry, galleries, overhanging fa{\c{c}}ades and vegetation on thermal comfort in urban street canyons - Solar Energy.pdf:pdf},
issn = {0038092X},
journal = {Solar Energy},
keywords = {asymmetry,dry climate,envi-met,gallery,hot,human thermal comfort,modelling,numerical,overhangs,physiologically equivalent temperature pet,shading device,street design,urban canyon},
number = {6},
pages = {742--754},
title = {{Effects of asymmetry, galleries, overhanging fa{\c{c}}ades and vegetation on thermal comfort in urban street canyons}},
volume = {81},
year = {2007}
}
@inproceedings{Mills2015,
author = {Mills, Gerald and Bechtel, Benjamin and Ching, Jason and See, Linda and Feddema, Johan and Foley, Michael and Alexander, Paul and Connor, Martin O},
booktitle = {ICUC9 - 9th International Conference on Urban Climate jointly with 12th Symposium on the Urban Environment},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Mills et al. - 2015 - An Introduction to the WUDAPT project - ICUC9 - 9th International Conference on Urban Climate jointly with 12th Sy.pdf:pdf},
title = {{An Introduction to the WUDAPT project}},
year = {2015}
}
@article{Gong2018,
author = {Gong, Fang-Ying and Zeng, Zhao-Cheng and Zhang, Fan and Li, Xiaojiang and Ng, Edward and Norford, Leslie K},
doi = {10.1016/j.buildenv.2018.02.042},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/1-s2.0-S0360132318301148-main.pdf:pdf},
issn = {0360-1323},
journal = {Building and Environment},
keywords = {Deep learning,Google Street View,High density,Street canyon,Street trees,View factor},
pages = {155--167},
publisher = {Elsevier},
title = {{Mapping sky, tree, and building view factors of street canyons in a high-density urban environment}},
volume = {134},
year = {2018}
}
@article{Badrinarayanan2017,
abstract = {We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network. The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN and also with the well known DeepLab-LargeFOV, DeconvNet architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. We show that SegNet provides good performance with competitive inference time and more efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.},
archivePrefix = {arXiv},
arxivId = {1511.00561},
author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
doi = {10.1109/TPAMI.2016.2644615},
eprint = {1511.00561},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Badrinarayanan, Kendall, Cipolla - 2017 - SegNet A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation - IEEE Transac.pdf:pdf},
isbn = {9783319464879},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Deep convolutional neural networks,decoder,encoder,indoor scenes,pooling,road scenes,semantic pixel-wise segmentation,upsampling},
number = {12},
pages = {2481--2495},
pmid = {28060704},
title = {{SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation}},
volume = {39},
year = {2017}
}
@inproceedings{Holder2016,
author = {Holder, Christopher J. and Breckon, Toby P. and Wei, Xiong},
booktitle = {European Conference on Computer Vision-ECCV 2016: Computer Vision – ECCV 2016 Workshops},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/holder16offroad.pdf:pdf},
pages = {149--162},
title = {{From On-Road to Off: Transfer Learning within a Deep Convolutional Neural Network for Segmentation and Classification of Off-Road Scenes}},
year = {2016}
}
@article{Middel2019,
author = {Middel, Ariane and Lukasczyk, Jonas and Zakrzewski, Sophie and Arnold, Michael and Maciejewski, Ross},
doi = {10.1016/j.landurbplan.2018.12.001},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Middel et al. - 2019 - Urban form and composition of street canyons A human-centric big data and deep learning approach - Landscape and.pdf:pdf},
issn = {0169-2046},
journal = {Landscape and Urban Planning},
keywords = {Deep learning,Google Street View,Human-centric,Spherical fractions,Street canyon,Urban form and composition,urban form and composition},
pages = {122--132},
publisher = {Elsevier},
title = {{Urban form and composition of street canyons: A human-centric big data and deep learning approach}},
volume = {183},
year = {2019}
}
@article{Nice2019Data,
author = {Nice, Kerry A. and Wijnands, Jasper S.},
journal = {Data in Brief},
pages = {},
publisher = {Elsevier},
title = {{Data set for: Sky pixel detection in outdoor imagery using an adaptive algorithm and machine learning.}},
volume = {},
year = {Submitted}
}
@misc{Mihail2015,
author = {Mihail, R. Paul},
url = {https://mypages.valdosta.edu/rpmihail/skyfinder/},
title = {{Skyfinder Dataset}},
year = {2015}
}
@article{Nice2019UC,
author = {Nice, K. A. and Wijnands, J. S. and Middel, A. and Wang, J. and Qiu, Y. and Zhao, N. and Thompson, J. and Aschwanden, G.D.P.A. and Zhao, H. and Stevenson, H.},
journal = {Urban Climate},
pages = {},
publisher = {Elsevier},
title = {{Sky pixel detection in outdoor imagery using an adaptive algorithm and machine learning.}},
volume = {},
year = {Submitted}
}
@article{Shen2018,
author = {Shen, Qiaomu and Zeng, Wei and Ye, Yu and Stefan, M and Schubiger, Simon and Burkhard, Remo and Qu, Huamin},
doi = {10.1109/TVCG.2017.2744159},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Shen et al. - 2018 - StreetVizor Visual Exploration of Human-Scale Urban Forms Based on Street Views - IEEE Transactions on Visualizatio.pdf:pdf},
journal = {IEEE Transactions on Visualization and Computer Graphics},
number = {1},
pages = {1004--1013},
title = {{StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views}},
volume = {24},
year = {2018}
}
@article{Liang2017,
author = {Liang, Jianming and Gong, Jianhua and Sun, Jun and Zhou, Jieping and Li, Wenhang and Li, Yi and Liu, Jin and Shen, Shen},
doi = {10.3390/rs9050411},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Liang et al. - 2017 - Automatic Sky View Factor Estimation from Street View Photographs—A Big Data Approach - Remote Sensing.pdf:pdf},
issn = {2072-4292},
journal = {Remote Sensing},
keywords = {automatic extraction,google street view,panorama,sky view factor,urban climate},
number = {5},
pages = {411},
title = {{Automatic Sky View Factor Estimation from Street View Photographs—A Big Data Approach}},
volume = {9},
year = {2017}
}
@article{Willmott1981,
author = {Willmott, Cort J.},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Willmott - 1981 - On the Validation of Models - Physical Geography.pdf:pdf},
journal = {Physical Geography},
number = {2},
pages = {184--194},
title = {{On the Validation of Models}},
volume = {2},
year = {1981}
}
@article{Tsai2016,
abstract = {Y.-H. Tsai, X. Shen, Z. Lin, K. Sunkavalli, and M.-H. Yang. Sky is not the limit: Semantic-aware sky replacement. ACM Transactions on Graphics (TOG), 35(4):149, 2016.},
author = {Tsai, Y.-H. and Shen, X. and Lin, Z. and Sunkavalli, K. and Yang, M.-H.},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/SkyReplacement{\_}SIG16.pdf:pdf},
isbn = {9781450342797},
journal = {ACM Transactions on Graphics},
keywords = {ap-,compositing,computational photography,computing methodologies,concepts,image processing,pearance transfer,semantic search,sky replacement,sky segmentation},
number = {4},
pages = {149},
title = {{Sky is Not the Limit: Semantic-Aware Sky Replacement}},
volume = {35},
year = {2016}
}
@inproceedings{Roser2008,
author = {Roser, Martin and Moosmann, Frank},
booktitle = {2008 IEEE Intelligent Vehicles Symposium},
doi = {10.1109/IVS.2008.4621205},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Roser, Moosmann - 2008 - Classification of Weather Situations on Single Color Images - 2008 IEEE Intelligent Vehicles Symposium.pdf:pdf},
isbn = {9781424425693},
pages = {798--803},
title = {{Classification of Weather Situations on Single Color Images}},
year = {2008}
}
@inproceedings{Tighe2010,
author = {Tighe, Joseph and Lazebnik, Svetlana},
booktitle = {European Conference on Computer Vision, ECCV 2010: Computer Vision – ECCV 2010},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Tighe, Lazebnik - 2010 - SuperParsing Scalable Nonparametric Image Parsing with Superpixels - European Conference on Computer Vision,.pdf:pdf},
keywords = {image parsing,image segmentation,scene understanding},
pages = {352--365},
title = {{SuperParsing: Scalable Nonparametric Image Parsing with Superpixels}},
year = {2010}
}
@inproceedings{Hoiem2005,
author = {Hoiem, Derek and Efros, Alexei A. and Hebert, Martial},
booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
doi = {10.1109/ICCV.2005.107},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Hoiem{\_}Geometric.pdf:pdf},
title = {{Geometric Context from a Single Image}},
year = {2005}
}
@article{Laffont2014,
author = {Laffont, P.-Y. and Ren, Z. and Tao, X. and Qian, C. and Hays, J.},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/TransientAttributes-paper.pdf:pdf},
journal = {ACM Transactions on Graphics},
keywords = {attribute-based image editing,image database},
number = {4},
title = {{Transient Attributes for High-Level Understanding and Editing of Outdoor Scenes}},
volume = {33},
year = {2014}
}
@article{Tao2009,
author = {Tao, Litian and Yuan, Lu and Sun, Jian},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/Tao, Yuan, Sun - 2009 - SkyFinder Attribute-based Sky Image Search - ACM Transaction on Graphics, Siggraph.pdf:pdf},
journal = {ACM Transaction on Graphics, Siggraph},
pages = {68},
title = {{SkyFinder : Attribute-based Sky Image Search}},
volume = {28},
year = {2009}
}
@misc{Nice2019SkyCode,
author = {Nice, Kerry A.},
howpublished = {https://bitbucket.org/politemadness/skypixeldetection},
title = {{Code repostory for 'Sky pixel detection in outdoor imagery using an adaptive algorithm and machine learning'.}},
year = {2019}
}
@article{Rueden2017,
author = {Rueden, Curtis T and Schindelin, Johannes and Hiner, Mark C and Dezonia, Barry E and Walter, Alison E and Arena, Ellen T and Eliceiri, Kevin W},
doi = {10.1186/s12859-017-1934-z},
file = {:home/kerryn/Documents/Work/PhDResearch/GeneralArticles/s12859-017-1934-z:},
journal = {BMC Bioinformatics},
keywords = {computational instrumentation,correspondence,edu,eliceiri,extensibility,image processing,imagej,imagej2,interoperability,laboratory for optical and,n-dimensional,open,open development,reproducibility,source,university of,wisc},
number = {529},
pages = {1--26},
publisher = {BMC Bioinformatics},
title = {{ImageJ2 : ImageJ for the next generation of scientific image data}},
volume = {18},
year = {2017}
}
